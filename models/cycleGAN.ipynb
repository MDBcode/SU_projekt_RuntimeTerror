{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cycleGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNS2uVqIgOYQTU/etu91SuA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from random import random\n","from numpy import load\n","from numpy import zeros\n","from numpy import ones\n","from numpy import asarray\n","from numpy.random import randint\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import plot_model\n","from keras.initializers import RandomNormal\n","from keras.models import Model\n","from keras.models import Input\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Activation\n","from keras.layers import Concatenate\n","from matplotlib import pyplot"],"metadata":{"id":"azrGAvKBcDud","executionInfo":{"status":"ok","timestamp":1656358436093,"user_tz":-120,"elapsed":268,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqWd7AN5dNX8","executionInfo":{"status":"ok","timestamp":1656358441798,"user_tz":-120,"elapsed":4976,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}},"outputId":"203e06a3-0c26-4405-99fa-b8a7efb06d3d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from keras.layers import Layer, InputSpec\n","from keras import initializers, regularizers, constraints\n","from keras import backend as K\n","\n","\n","class InstanceNormalization(Layer):\n","    \"\"\"Instance normalization layer.\n","    Normalize the activations of the previous layer at each step,\n","    i.e. applies a transformation that maintains the mean activation\n","    close to 0 and the activation standard deviation close to 1.\n","    # Arguments\n","        axis: Integer, the axis that should be normalized\n","            (typically the features axis).\n","            For instance, after a `Conv2D` layer with\n","            `data_format=\"channels_first\"`,\n","            set `axis=1` in `InstanceNormalization`.\n","            Setting `axis=None` will normalize all values in each\n","            instance of the batch.\n","            Axis 0 is the batch dimension. `axis` cannot be set to 0 to avoid errors.\n","        epsilon: Small float added to variance to avoid dividing by zero.\n","        center: If True, add offset of `beta` to normalized tensor.\n","            If False, `beta` is ignored.\n","        scale: If True, multiply by `gamma`.\n","            If False, `gamma` is not used.\n","            When the next layer is linear (also e.g. `nn.relu`),\n","            this can be disabled since the scaling\n","            will be done by the next layer.\n","        beta_initializer: Initializer for the beta weight.\n","        gamma_initializer: Initializer for the gamma weight.\n","        beta_regularizer: Optional regularizer for the beta weight.\n","        gamma_regularizer: Optional regularizer for the gamma weight.\n","        beta_constraint: Optional constraint for the beta weight.\n","        gamma_constraint: Optional constraint for the gamma weight.\n","    # Input shape\n","        Arbitrary. Use the keyword argument `input_shape`\n","        (tuple of integers, does not include the samples axis)\n","        when using this layer as the first layer in a Sequential model.\n","    # Output shape\n","        Same shape as input.\n","    # References\n","        - [Layer Normalization](https://arxiv.org/abs/1607.06450)\n","        - [Instance Normalization: The Missing Ingredient for Fast Stylization](\n","        https://arxiv.org/abs/1607.08022)\n","    \"\"\"\n","    def __init__(self,\n","                 axis=None,\n","                 epsilon=1e-3,\n","                 center=True,\n","                 scale=True,\n","                 beta_initializer='zeros',\n","                 gamma_initializer='ones',\n","                 beta_regularizer=None,\n","                 gamma_regularizer=None,\n","                 beta_constraint=None,\n","                 gamma_constraint=None,\n","                 **kwargs):\n","        super(InstanceNormalization, self).__init__(**kwargs)\n","        self.supports_masking = True\n","        self.axis = axis\n","        self.epsilon = epsilon\n","        self.center = center\n","        self.scale = scale\n","        self.beta_initializer = initializers.get(beta_initializer)\n","        self.gamma_initializer = initializers.get(gamma_initializer)\n","        self.beta_regularizer = regularizers.get(beta_regularizer)\n","        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n","        self.beta_constraint = constraints.get(beta_constraint)\n","        self.gamma_constraint = constraints.get(gamma_constraint)\n","\n","    def build(self, input_shape):\n","        ndim = len(input_shape)\n","        if self.axis == 0:\n","            raise ValueError('Axis cannot be zero')\n","\n","        if (self.axis is not None) and (ndim == 2):\n","            raise ValueError('Cannot specify axis for rank 1 tensor')\n","\n","        self.input_spec = InputSpec(ndim=ndim)\n","\n","        if self.axis is None:\n","            shape = (1,)\n","        else:\n","            shape = (input_shape[self.axis],)\n","\n","        if self.scale:\n","            self.gamma = self.add_weight(shape=shape,\n","                                         name='gamma',\n","                                         initializer=self.gamma_initializer,\n","                                         regularizer=self.gamma_regularizer,\n","                                         constraint=self.gamma_constraint)\n","        else:\n","            self.gamma = None\n","        if self.center:\n","            self.beta = self.add_weight(shape=shape,\n","                                        name='beta',\n","                                        initializer=self.beta_initializer,\n","                                        regularizer=self.beta_regularizer,\n","                                        constraint=self.beta_constraint)\n","        else:\n","            self.beta = None\n","        self.built = True\n","\n","    def call(self, inputs, training=None):\n","        input_shape = K.int_shape(inputs)\n","        reduction_axes = list(range(0, len(input_shape)))\n","\n","        if self.axis is not None:\n","            del reduction_axes[self.axis]\n","\n","        del reduction_axes[0]\n","\n","        mean = K.mean(inputs, reduction_axes, keepdims=True)\n","        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon\n","        normed = (inputs - mean) / stddev\n","\n","        broadcast_shape = [1] * len(input_shape)\n","        if self.axis is not None:\n","            broadcast_shape[self.axis] = input_shape[self.axis]\n","\n","        if self.scale:\n","            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n","            normed = normed * broadcast_gamma\n","        if self.center:\n","            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n","            normed = normed + broadcast_beta\n","        return normed\n","\n","    def get_config(self):\n","        config = {\n","            'axis': self.axis,\n","            'epsilon': self.epsilon,\n","            'center': self.center,\n","            'scale': self.scale,\n","            'beta_initializer': initializers.serialize(self.beta_initializer),\n","            'gamma_initializer': initializers.serialize(self.gamma_initializer),\n","            'beta_regularizer': regularizers.serialize(self.beta_regularizer),\n","            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),\n","            'beta_constraint': constraints.serialize(self.beta_constraint),\n","            'gamma_constraint': constraints.serialize(self.gamma_constraint)\n","        }\n","        base_config = super(InstanceNormalization, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"metadata":{"id":"tDHnofAAeN2v","executionInfo":{"status":"ok","timestamp":1656358441799,"user_tz":-120,"elapsed":8,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# define the Discriminator model: 70x70 patchGAN\n","\n","def discriminator(image_shape):\n","  init = RandomNormal(stddev=0.02)  # weight initialization\n","  in_image = Input(shape=image_shape)  # source image input\n","  \n","  d = Conv2D(64, (4,4), strides=(2,2), padding=\"same\", kernel_initializer=init)(in_image)  # C64: 4x4 kernel, stride=2x2\n","  d = LeakyReLU(alpha=0.2)(d)\n","  d = Conv2D(128, (4,4), strides=(2,2), padding=\"same\", kernel_initializer=init)(d)  # C128: 4x4 kernel, stride=2x2\n","  d = InstanceNormalization(axis=-1)(d)\n","  d = LeakyReLU(alpha=0.2)(d)\n","  d = Conv2D(256, (4,4), strides=(2,2), padding=\"same\", kernel_initializer=init)(d)  # C256: 4x4 kernel, stride=2x2\n","  d = InstanceNormalization(axis=-1)(d)\n","  d = LeakyReLU(alpha=0.2)(d)\n","  \n","  d = Conv2D(512, (4,4), padding=\"same\", kernel_initializer=init)(d)  # second last output layer : 4x4 kernel, stride=1x1\n","  d = InstanceNormalization(axis=-1)(d)\n","  d = LeakyReLU(alpha=0.2)(d)\n","  \n","  patch_out = Conv2D(1, (4,4), padding=\"same\", kernel_initializer=init)(d)  # patch output\n","  \n","  model = Model(inputs=in_image, outputs=patch_out)\n","  model.compile(loss=\"mse\", optimizer=Adam(lr=0.0002, beta_1=0.5), loss_weights=[0.5])  # compile model\n","  plot_model(model, to_file='/content/drive/MyDrive/Strojno_projekt/models/discriminator_cycleGAN.png', show_shapes=True)\n","\n","  return model"],"metadata":{"id":"44lIPerHgVh0","executionInfo":{"status":"ok","timestamp":1656358441799,"user_tz":-120,"elapsed":7,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# residual block that contains two 3×3 convolutional layers with the same number of filters on both layers\n","\n","def resnet_block(n_filters, input_layer):\n","\tinit = RandomNormal(stddev=0.02)  # weight initialization\n","\t\n","\tg = Conv2D(n_filters, (3,3), padding=\"same\", kernel_initializer=init)(input_layer)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\tg = Activation(\"relu\")(g)\n","\t\n","\tg = Conv2D(n_filters, (3,3), padding=\"same\", kernel_initializer=init)(g)\n","\tg = InstanceNormalization(axis=-1)(g)\n","\t\n","\tg = Concatenate()([g, input_layer])  # concatenate channel-wise with input layer\n","\n","\treturn g"],"metadata":{"id":"m7HG_DtXhy8J","executionInfo":{"status":"ok","timestamp":1656358441799,"user_tz":-120,"elapsed":7,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# define the Generator model: encoder-decoder type architecture\n","# c7s1-k =  7×7 Convolution-InstanceNorm-ReLU layer with k filters and stride 1. \n","# dk = 3×3 Convolution-InstanceNorm-ReLU layer with k filters and stride 2.\n","# Rk = residual block that contains two 3×3 convolutional layers\n","# uk = 3×3 fractional-strided-Convolution InstanceNorm-ReLU layer with k filters and stride 1/2\n","\n","def generator(image_shape, n_resnet=9):\n","  init = RandomNormal(stddev=0.02)  # weight initialization\n","  in_image = Input(shape=image_shape)  # image input\n","  \n","  # c7s1-64\n","  g = Conv2D(64, (7,7), padding=\"same\", kernel_initializer=init)(in_image)\n","  g = InstanceNormalization(axis=-1)(g)\n","  g = Activation(\"relu\")(g)\n","\n","  # d128\n","  g = Conv2D(128, (3,3), strides=(2,2), padding=\"same\", kernel_initializer=init)(g)\n","  g = InstanceNormalization(axis=-1)(g)\n","  g = Activation(\"relu\")(g)\n","\n","  # d256\n","  g = Conv2D(256, (3,3), strides=(2,2), padding=\"same\", kernel_initializer=init)(g)\n","  g = InstanceNormalization(axis=-1)(g)\n","  g = Activation(\"relu\")(g)\n","  \n","  # R256\n","  for _ in range(n_resnet):\n","    g = resnet_block(256, g)\n","  \n","  # u128\n","  g = Conv2DTranspose(128, (3,3), strides=(2,2), padding=\"same\", kernel_initializer=init)(g)\n","  g = InstanceNormalization(axis=-1)(g)\n","  g = Activation(\"relu\")(g)\n","\n","  # u64\n","  g = Conv2DTranspose(64, (3,3), strides=(2,2), padding=\"same\", kernel_initializer=init)(g)\n","  g = InstanceNormalization(axis=-1)(g)\n","  g = Activation(\"relu\")(g)\n","\n","  # c7s1-3\n","  g = Conv2D(3, (7,7), padding=\"same\", kernel_initializer=init)(g)\n","  g = InstanceNormalization(axis=-1)(g)\n","  out_image = Activation(\"tanh\")(g)\n","  \n","  model = Model(inputs=in_image, outputs=out_image)\n","  plot_model(model, to_file='/content/drive/MyDrive/Strojno_projekt/models/generator_cycleGAN.png', show_shapes=True)\n","\n","  return model"],"metadata":{"id":"j64ExxFKiaxN","executionInfo":{"status":"ok","timestamp":1656358441800,"user_tz":-120,"elapsed":8,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# define a composite model for updating generators by adversarial and cycle loss\n","\n","def composite_model(g_model_1, d_model, g_model_2, image_shape):\n","  g_model_1.trainable = True\n","  d_model.trainable = False\n","  g_model_2.trainable = False\n","    \n","  # adversarial loss\n","  input_gen = Input(shape=image_shape)\n","  gen1_out = g_model_1(input_gen)\n","  output_d = d_model(gen1_out)\n","\n","  # identity loss\n","  input_id = Input(shape=image_shape)\n","  output_id = g_model_1(input_id)\n","\n","  # cycle loss - forward\n","  output_f = g_model_2(gen1_out)\n","\n","  # cycle loss - backward\n","  gen2_out = g_model_2(input_id)\n","  output_b = g_model_1(gen2_out)\n","    \n","  # define model graph\n","  model = Model(inputs=[input_gen, input_id], outputs=[output_d, output_id, output_f, output_b])\n","  \n","  opt = Adam(lr=0.0002, beta_1=0.5)\n","  model.compile(loss=[\"mse\", \"mae\", \"mae\", \"mae\"], loss_weights=[1, 5, 10, 10], optimizer=opt)\n","  plot_model(model, to_file='/content/drive/MyDrive/Strojno_projekt/models/gan_cycleGAN.png', show_shapes=True)\n","\n","  return model"],"metadata":{"id":"SgmUvx2YkdGB","executionInfo":{"status":"ok","timestamp":1656358441800,"user_tz":-120,"elapsed":7,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# load and prepare training images\n","\n","def load_real_samples(filename):\n","  data = load(filename)\n","  X1, X2 = data[\"arr_0\"], data[\"arr_1\"]\n","\t\n","  # [0,255] -> [-1,1]\n","  X1 = (X1 - 127.5) / 127.5\n","  X2 = (X2 - 127.5) / 127.5\n","\n","  return [X1, X2]"],"metadata":{"id":"N1PESGf3k-Pr","executionInfo":{"status":"ok","timestamp":1656358441800,"user_tz":-120,"elapsed":7,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# select a batch of random samples, returns images and target\n","\n","def generate_real_samples(dataset, n_samples, patch_shape):\n","\tix = randint(0, dataset.shape[0], n_samples)  # choose random instances\n","\tX = dataset[ix]\n","\n","\ty = ones((n_samples, patch_shape, patch_shape, 1))\n"," \n","\treturn X, y"],"metadata":{"id":"gKUp32RulVSM","executionInfo":{"status":"ok","timestamp":1656358441800,"user_tz":-120,"elapsed":7,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# generate a batch of images, returns images and targets\n"," \n","def generate_fake_samples(g_model, dataset, patch_shape):\n","\tX = g_model.predict(dataset)\n"," \n","\ty = zeros((len(X), patch_shape, patch_shape, 1))\n","\n","\treturn X, y"],"metadata":{"id":"QrawPpPElhTn","executionInfo":{"status":"ok","timestamp":1656358441802,"user_tz":-120,"elapsed":9,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# periodically save the generator models to file\n","\n","def save_models(step, g_model_AtoB, g_model_BtoA):\n","\tfilename1 = \"/content/drive/MyDrive/Strojno_projekt/models/cycleGAN_saved_models/g_model_AtoB_%06d.h5\" % (step+1)  # save the first generator model\n","\tg_model_AtoB.save(filename1)\n","\t\n","\tfilename2 = \"/content/drive/MyDrive/Strojno_projekt/models/cycleGAN_saved_models/g_model_BtoA_%06d.h5\" % (step+1)  # save the second generator model\n","\tg_model_BtoA.save(filename2)\n"," \n","\tprint(\"\\n\")\n","\tprint(\">Saved: %s and %s\" % (filename1, filename2))"],"metadata":{"id":"5ogX7bgslqaO","executionInfo":{"status":"ok","timestamp":1656358441802,"user_tz":-120,"elapsed":9,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# periodically generate images using the save model and plot input and output images\n","\n","def summarize_performance(step, g_model, trainX, name, n_samples=5):\n","\tX_in, _ = generate_real_samples(trainX, n_samples, 0)  # select a sample of input images\n","\tX_out, _ = generate_fake_samples(g_model, X_in, 0)  # generate translated images\n","\t# [-1,1] -> [0,1]\n","\tX_in = (X_in + 1) / 2.0\n","\tX_out = (X_out + 1) / 2.0\n","\t\n","  # plot real images\n","\tfor i in range(n_samples):\n","\t\tpyplot.subplot(2, n_samples, 1 + i)\n","\t\tpyplot.axis(\"off\")\n","\t\tpyplot.imshow(X_in[i])\n","\t# plot translated image\n","\tfor i in range(n_samples):\n","\t\tpyplot.subplot(2, n_samples, 1 + n_samples + i)\n","\t\tpyplot.axis(\"off\")\n","\t\tpyplot.imshow(X_out[i])\n","\t# save plot to file\n","\tfilename1 = \"/content/drive/MyDrive/Strojno_projekt/models/cycleGAN_saved_models/%s_generated_plot_%06d.png\" % (name, (step+1))\n","\tpyplot.savefig(filename1)\n","\tpyplot.close()"],"metadata":{"id":"7F3JV5zel1QO","executionInfo":{"status":"ok","timestamp":1656358441802,"user_tz":-120,"elapsed":8,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# update image pool for fake images to reduce model oscillation\n","# update discriminators using a history of generated images rather than the ones produced by the latest generators\n","\n","def update_image_pool(pool, images, max_size=50):\n","\tselected = []\n","\tfor image in images:\n","\t\tif len(pool) < max_size:\n","\t\t\t# stock the pool\n","\t\t\tpool.append(image)\n","\t\t\tselected.append(image)\n","\t\telif random() < 0.5:\n","\t\t\t# use image, but don't add it to the pool\n","\t\t\tselected.append(image)\n","\t\telse:\n","\t\t\t# replace an existing image and use replaced image\n","\t\t\tix = randint(0, len(pool))\n","\t\t\tselected.append(pool[ix])\n","\t\t\tpool[ix] = image\n","      \n","\treturn asarray(selected)"],"metadata":{"id":"rXPAaIRYmNtM","executionInfo":{"status":"ok","timestamp":1656358441803,"user_tz":-120,"elapsed":9,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","execution_count":28,"metadata":{"id":"ODVQT4bkuRfS","executionInfo":{"status":"ok","timestamp":1656358441803,"user_tz":-120,"elapsed":9,"user":{"displayName":"Marko Domagoj Benković","userId":"00287224075371748076"}}},"outputs":[],"source":["# train cycleGAN models\n","\n","def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset, epochs=5):\n","\tn_epochs, batch_size = epochs, 1\n","\tn_patch = d_model_A.output_shape[1]  # determine the output square shape of the discriminator\n","\n","\ttrainA, trainB = dataset\n","\tpoolA, poolB = [], []\n","\tbat_per_epo = int(len(trainA) / batch_size)\n","\tn_steps = bat_per_epo * n_epochs  # number of iterations\n","\n","\tdA1_losses, dA2_losses = [], []\n","\tdB1_losses, dB2_losses = [], []\n","\tg1_losses, g2_losses = [], []\n","    \n","\t# manually enumerate iterations\n","\tfor i in range(n_steps):\n","\t\t# select a batch of real samples from each domain (A and B)\n","\t\tX_realA, y_realA = generate_real_samples(trainA, batch_size, n_patch)\n","\t\tX_realB, y_realB = generate_real_samples(trainB, batch_size, n_patch)\n","\t\n","\t\t# generate a batch of fake samples using both B to A and A to B generators\n","\t\tX_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n","\t\tX_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n","\t\n","\t\t# update fake images in the pool\n","\t\tX_fakeA = update_image_pool(poolA, X_fakeA)\n","\t\tX_fakeB = update_image_pool(poolB, X_fakeB)\n","        \n","\t\t# update generator B->A via the composite model\n","\t\tg_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n","\t\n","\t\t# update discriminator for A -> [real/fake]\n","\t\tdA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n","\t\tdA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n","\t\t\n","    # update generator A->B via the composite model\n","\t\tg_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n","\t\n","\t\t# update discriminator for B -> [real/fake]\n","\t\tdB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n","\t\tdB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n","\t\t\n","\t\tprint(\"Iteration>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]\" % (i+1, dA_loss1, dA_loss2, dB_loss1, dB_loss2, g_loss1, g_loss2))\n","\t\t# summarize performance\t\n","\t\tif (i+1) % (bat_per_epo//4) == 0:\n","\t\t\tdA1_losses.append(dA_loss1)\n","\t\t\tdA2_losses.append(dA_loss2)\n","\t\t\tdB1_losses.append(dB_loss1)\n","\t\t\tdB2_losses.append(dB_loss2)\n","\t\t\tg1_losses.append(g_loss1)\n","\t\t\tg2_losses.append(g_loss2)\n","\t\t\t\n","\t\tif (i+1) % bat_per_epo == 0:\n","\t\t\tsummarize_performance(i, g_model_AtoB, trainA, \"AtoB\")  # plot A->B translation\n","\t\t\tsummarize_performance(i, g_model_BtoA, trainB, \"BtoA\")  # plot B->A translation\n","\t\t\tsave_models(i, g_model_AtoB, g_model_BtoA)\n","\t \n","\tpyplot.plot(dA1_losses)\n","\tpyplot.xlabel(\"Epoch\")\n","\tpyplot.ylabel(\"Loss\")\n","\tpyplot.title(\"DiscriminatorA1 loss\")\n","\tpyplot.show()\n","\n","\tpyplot.plot(dA2_losses)\n","\tpyplot.xlabel(\"Epoch\")\n","\tpyplot.ylabel(\"Loss\")\n","\tpyplot.title(\"DiscriminatorA2 loss\")\n","\tpyplot.show()\n","\n","\tpyplot.plot(dB1_losses)\n","\tpyplot.xlabel(\"Epoch\")\n","\tpyplot.ylabel(\"Loss\")\n","\tpyplot.title(\"DiscriminatorB1 loss\")\n","\tpyplot.show()\n","\n","\tpyplot.plot(dB2_losses)\n","\tpyplot.xlabel(\"Epoch\")\n","\tpyplot.ylabel(\"Loss\")\n","\tpyplot.title(\"DiscriminatorB2 loss\")\n","\tpyplot.show()\n"," \n","\tpyplot.plot(g1_losses)\n","\tpyplot.xlabel(\"Epoch\")\n","\tpyplot.ylabel(\"Loss\")\n","\tpyplot.title(\"Generator1 loss\")\n","\tpyplot.show()\n","\n","\tpyplot.plot(g2_losses)\n","\tpyplot.xlabel(\"Epoch\")\n","\tpyplot.ylabel(\"Loss\")\n","\tpyplot.title(\"Generator2 loss\")\n","\tpyplot.show()"]}]}